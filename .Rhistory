mcmc_mat[str_extract(rownames(mcmc_mat), pattern = "(\\w+)\\[(\\d+)\\]") %in% rownames(mcmc_mat),]
par_inst <- mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),]
colnames(par_inst)
rownames(par_inst)
str_extract(rownames(par_inst), pattern = "(\\w+)\\[(\\d+)\\]", group = 2)
str_extract(rownames(par_inst), pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst$var <- str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst
par_inst <- mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),]
c(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1))
par_inst$var <- c(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1))
par_inst %>%
mutate(vars = str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1))
par_inst <- mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),]
par_inst %>%
mutate(vars = str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1))
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst
instlist <- c(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1))
par_inst$variables <- instlist
# Select results, transpose, change column names
par_overall <- as.data.frame(t(mcmc_mat[rownames(mcmc_mat) %in%
par_homes$overall,]))
par_daily <- as.data.frame(t(mcmc_mat[rownames(mcmc_mat) %in%
par_homes$daily,]))
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
par_inst <-
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
instlist
par_inst$variables <- instlist
par_inst
par_inst$vars <- str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst
t(par_inst)
?pivot_longer
pivot_longer(par_inst, cols = mean:Rhat)
par_inst <-
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
par_inst$vars <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
pivot_longer(par_inst, cols = mean:Rhat)
par_inst <- pivot_longer(par_inst, cols = mean:Rhat)
pivot_wider(par_inst, names_from = vars)
pivot_wider(par_inst, names_from = vars, values_from = value)
par_inst <-
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
# Extract variable name and index number from column name
par_inst$vars <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst$index <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2)
par_inst
pivot_longer(par_inst, cols = mean:Rhat)
par_inst <- pivot_longer(par_inst, cols = mean:Rhat)
pivot_wider(par_inst, names_from = vars, values_from = c(value, index))
pivot_wider(par_inst, names_from = name, values_from = c(value, index))
par_inst
par_inst <-
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
par_inst
# Extract variable name and index number from column name
par_inst$vars <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst$index <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2)
par_inst
par_inst <- pivot_longer(par_inst, cols = c(mean:Rhat, index))
par_inst$index <-
as.numeric(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2))
pivot_longer(par_inst, cols = c(mean:Rhat, index))
par_inst <- pivot_longer(par_inst, cols = c(mean:Rhat, index))
par_inst
View(par_inst)
pivot_wider(par_inst, names_from = name, values_from = value)
par_inst <-
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
# Extract variable name and index number from column name
par_inst$vars <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst$index <-
as.numeric(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2))
par_inst <- pivot_longer(par_inst, cols = mean:Rhat)
par_inst
pivot_wider(par_inst, names_from = name, values_from = value)
pivot_wider(par_inst, names_from = name, values_from = c(vars, value))
pivot_wider(par_inst, names_from = c(vars, name), values_from = value)
# Pivot dataframe to wide
par_inst <- pivot_wider(par_inst, names_from = c(vars, name),
values_from = value)
# Next: need to change "index" to "datetime" but maybe that happens outside of
# this function (in conjunction with adding a date to the daily data)
list(
overall = par_overall,
daily = par_daily,
inst = par_inst
)
list(
overall = par_overall,
daily = par_daily,
inst = par_inst
)
runmcmc_out
ar_table
var_table
runstan_out
data_list
data_all
data_prepped
data = data_all
data
# Add date column if not there already
data$date <- lubridate::date(data$solar.time)
# Glue location names together
location.names <- c(up.name, down.name)
# NOTE: fixing number of days here for now, but in future this should be
# modified to reflect the number of days of data passed to the prep data
# function
d <- 1
# Get timesteps --------------------------------------------------------------
obs_times <- unique(data$solar.time)
# Grab time difference between measurements, min
timestep_min <- round(as.numeric(obs_times[2] - obs_times[1]))
# Calc n24, number of measurements in full 24 hours
n24 <- round(1 / (timestep_min / 1440))
# Get dates ------------------------------------------------------------------
obs_dates <- unique(data$date)
num_dates <- length(obs_dates)
# Get average parameters per date --------------------------------------------
data_daily <-
as.data.frame(
data %>%
group_by(date) %>%
summarise(# mean travel time
tt_min = mean(tt),
# mean lag
lag = round(tt_min / timestep_min),
# mean depth
depth = mean(depth),
# mean discharge
discharge = mean(discharge)))
data_daily
# Pivot dataset wider --------------------------------------------------------
# Rename location names to s1 and s2
data$location <-
case_match(data$location,
location.names[1] ~ "s1",
location.names[2] ~ "s2")
data$location
up.name = "upstream"
down.name = "downstream"
# Add date column if not there already
data$date <- lubridate::date(data$solar.time)
# Glue location names together
location.names <- c(up.name, down.name)
# NOTE: fixing number of days here for now, but in future this should be
# modified to reflect the number of days of data passed to the prep data
# function
d <- 1
# Get timesteps --------------------------------------------------------------
obs_times <- unique(data$solar.time)
# Grab time difference between measurements, min
timestep_min <- round(as.numeric(obs_times[2] - obs_times[1]))
# Calc n24, number of measurements in full 24 hours
n24 <- round(1 / (timestep_min / 1440))
# Get dates ------------------------------------------------------------------
obs_dates <- unique(data$date)
num_dates <- length(obs_dates)
# Get average parameters per date --------------------------------------------
data_daily <-
as.data.frame(
data %>%
group_by(date) %>%
summarise(# mean travel time
tt_min = mean(tt),
# mean lag
lag = round(tt_min / timestep_min),
# mean depth
depth = mean(depth),
# mean discharge
discharge = mean(discharge)))
# Pivot dataset wider --------------------------------------------------------
# Rename location names to s1 and s2
data$location <-
case_match(data$location,
location.names[1] ~ "s1",
location.names[2] ~ "s2")
# Select only columns of interest, wide-transform dataset
data_wide <-
as.data.frame(data %>%
select(date, solar.time, location, DO.obs, DO.sat,
temp.water, light, depth) %>%
pivot_wider(names_from = location,
values_from = DO.obs:depth))
# Get number of unique observations per date ---------------------------------
date_table <- table(data_wide$date)
num_daily_obs <- unname(date_table)
# For future editing: loop over total number of dates here, separating data
# from each date into its own data_ply ---------------------------------------
data_ply <- data_wide[data_wide$date == ply_date,]
ply_date = "2024-09-19"
# For future editing: loop over total number of dates here, separating data
# from each date into its own data_ply ---------------------------------------
data_ply <- data_wide[data_wide$date == ply_date,]
daily_ply <- data_daily[data_daily$date == ply_date,]
obs_ply <- date_table[names(date_table) == ply_date]
daily_ply
data_ply
# Get start datetime on day
min(data_ply$solar.time)
# Get start datetime on day
starttime <- min(data_ply$solar.time)
# Initialize empty vectors for mean light fraction and water temperature
lightfrac <- vector(mode = "numeric", length = nobs)
temp <- vector(mode = "numeric", length = nobs)
# Pull day's parameters out of data_daily
tt_min <- daily_ply$tt_min
lag <- daily_ply$lag
depth <- daily_ply$depth
discharge <- daily_ply$discharge
moddate <- names(obs_ply)
nobs <- as.numeric(obs_ply)
# Get start datetime on day
starttime <- min(data_ply$solar.time)
# Initialize empty vectors for mean light fraction and water temperature
lightfrac <- vector(mode = "numeric", length = nobs)
temp <- vector(mode = "numeric", length = nobs)
depthvec <- vector(mode = "numeric", length = nobs)
# Loop through observations in day
for (i in 1:nobs){
# Mean light -------------------------------------------------------------
# Calculate fraction of daily light seen at upstream station
lightstep_s1 <- sum(data_ply$light_s1[i:(i+lag)])
lighttotal_s1 <- sum(data_ply$light_s1, na.rm = TRUE)
lightfrac_s1 <- lightstep_s1 / lighttotal_s1
# Calculate fraction of daily light seen at downstream station
lightstep_s2 <- sum(data_ply$light_s2[i:(i+lag)])
lighttotal_s2 <- sum(data_ply$light_s2, na.rm = TRUE)
lightfrac_s2 <- lightstep_s2 / lighttotal_s2
# Calculate mean light fraction, add to vector
lightfrac[i] <- mean(c(lightfrac_s1, lightfrac_s2), na.rm = TRUE)
# Mean water temperature -------------------------------------------------
temp[i] <- mean(c(data_ply$temp.water_s1[i:(i+lag)],
data_ply$temp.water_s2[i:(i+lag)]), na.rm = TRUE)
# Mean depth -------------------------------------------------------------
depthvec[i] <- mean(c(data_ply$depth_s1[i:(i+lag)],
data_ply$depth_s2[i:(i+lag)]), na.rm = TRUE)
}
load_all()
# Pass data and specs to prepping function #####################################
data_prepped <-
prepdata_bayes_twostation(data = data_all, ply_date = "2024-09-19",
specs = mod_specs)
# Pass data and specs to prepping function #####################################
,<-
data_prepped
# FOR TESTING
data_list <- data_prepped
#runstan_bayes <- function(data_list, specs, ){
# Pull out model name
model_name <- data_list$model_name
# Pull settings from specs list
ncores <- data_list$n_cores
n_chains <- data_list$n_chains
verbose <- data_list$verbose
warmup <- data_list$burnin_steps
iter <- data_list$saved_steps + warmup
thin_steps <- data_list$thin_steps
params_out <- data_list$params_out
keep_mcmc <- data_list$keep_mcmc
# Determine number of cores to use
tot_cores <- parallel::detectCores()
# Compare to number of cores specified in set_specs()
n_cores <- min(tot_cores, ncores)
# Tell user how many cores Stan is going to use so they can adjust settings
# if they want
if(verbose){message(paste0("\nStan requesting ", n_chains, " chains on ",
n_cores, " of ", tot_cores, " available cores."))}
# Get filepath to compiled & uncompiled stan model
model_path <- paste0("inst/stan/", model_name, ".stan")
mobj_path <- paste0("inst/stan/", model_name, ".rds")
# Check for existence of compiled model. If model doesn't exist, compile it.
if(file.exists(mobj_path)){
if(verbose){message(paste0("\nUsing previously compiled ", model_name,
" model: ", mobj_path))}
} else{
# Start clock for compilation time
start.time <- Sys.time()
# If file doesn't exist, compile model
if(verbose){message(paste0("\nCompiling ", model_name, ".stan model..."))}
stan_model(file = model_path, model_name = model_name, auto_write = TRUE,
warn_pedantic = TRUE, warn_uninitialized = TRUE)
# Stop clock
end.time <- Sys.time()
# Verify that compilation was successful & present done message
if(file.exists(mobj_path)){
elapsed <- round(as.numeric(end.time - start.time,
units = "hours") * 60 * 60,
digits = 2)
if(verbose){message(paste0("\nDone! Compile time was ", elapsed,
" seconds."))}
} else{
message("ERROR: Stan model was not compiled successfully. Try restarting your R session.")
}
}
stan_out <- format_mcmc_mat(mcmc_mat = stan_mat, names_params, names_stats,
keep_mcmc, runmcmc_out = runstan_out)
roxygenise()
roxygenise()
load_all()
# Format stan output
stan_out <- format_mcmc_mat(mcmc_mat = stan_mat, names_params, names_stats,
keep_mcmc, runmcmc_out = runstan_out)
stan_out
# Glue together stan_out list with date and datetime information from
# original data_list input
stan_out$overall
stan_out$daily
stan_out$inst
data_all
stan_out$inst$solar.time[1]
stan_out$inst$solar.time <- NA
# Set first entry to start time
stan_out$inst$solar.time[1]
# Set first entry to start time
stan_out$inst$solar.time[1] <- data_list$startTime
stan_out$inst$solar.time
data_list$startTime
str(stan_out$inst)
data_list$timestep
data_list$timestep * 60
# Loop through time index to calc solar time at each timestep
for (i in 2:nrow(stan_out$inst)){
stan_out$inst$solar.time[i] <-
stan_out$inst$solar.time[i-1] +
data_list$timestep * 60
}
stan_out$inst
View(stan_out)
View(stan_out[["inst"]])
# Convert from UNIX to UTC
as.POSIXct(stan_out$inst$solar.time)
# Convert from UNIX to UTC
as.POSIXct(stan_out$inst$solar.time, origin = "1970-01-01")
?as.POSIXct
# Convert from UNIX to UTC
as.POSIXct(stan_out$inst$solar.time, origin = "1970-01-01",
tz = "UTC")
data_list$startTime
# Convert from UNIX to UTC
stan_out$inst$solar.time <- as.POSIXct(stan_out$inst$solar.time,
origin = "1970-01-01",
tz = "UTC")
View(stan_out[["inst"]])
relocate(stan_out$inst, solar.time)
stan_out$inst <- relocate(stan_out$inst, solar.time)
View(stan_out[["inst"]])
stan_out
as.data.frame(t(mcmc_mat[rownames(mcmc_mat) %in%
par_homes$daily,]))
mcmc_mat[rownames(mcmc_mat) %in%
par_homes$daily,]
# Internal function for pivoting and widening model output df
pivotfunc <- function(data){
data <- pivot_longer(data, cols = mean:Rhat)
data <- pivot_wider(data, names_from = c(vars, name), values_from = value)
return(data)
}
par_inst <-
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
# Extract variable name and index number from column name
par_inst$vars <-
str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 1)
par_inst$datetime_index <-
as.numeric(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2))
pivotfunc(par_inst)
par_inst <- pivotfunc(par_inst)
# Internal function for pivoting and widening model output df
pivotfunc <- function(data){
data <- as.data.frame(data)
data <- pivot_longer(data, cols = mean:Rhat)
data <- pivot_wider(data, names_from = c(vars, name), values_from = value)
return(data)
}
par_daily <- mcmc_mat[rownames(mcmc_mat) %in%
par_homes$daily,]
pivotfunc(par_daily)
data = par_daily
par_daily
# Internal function for pivoting and widening model output df
pivotfunc <- function(data, varList){
data <- as.data.frame(data)
data$vars <- varList
data <- pivot_longer(data, cols = mean:Rhat)
data <- pivot_wider(data, names_from = c(vars, name), values_from = value)
return(data)
}
pivotfunc(par_daily, varList = rownames(par_daily))
# Daily estimates
par_daily <- mcmc_mat[rownames(mcmc_mat) %in% par_homes$daily,]
par_daily <- pivotfunc(par_daily, varList = rownames(par_daily))
par_daily
mcmc_mat[rownames(mcmc_mat) %in% par_homes$overall,]
# Overall estimates
par_overall <- mcmc_mat[rownames(mcmc_mat) %in% par_homes$overall,]
pivotfunc(par_overall, varList = rownames(par_overall))
par_overall <- pivotfunc(par_overall, varList = rownames(par_overall))
# Instantaneous estimates
par_inst <- mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),]
# Add indexing for date times
par_inst$datetime_index <-
as.numeric(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2))
as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
# Instantaneous estimates
par_inst <- as.data.frame(mcmc_mat[str_extract(rownames(mcmc_mat),
pattern = "(\\w+)\\[(\\d+)\\]") %in%
rownames(mcmc_mat),])
# Add indexing for date times
par_inst$datetime_index <-
as.numeric(str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]", group = 2))
par_inst <- pivotfunc(par_inst,
varList = str_extract(rownames(par_inst),
pattern = "(\\w+)\\[(\\d+)\\]",
group = 1))
par_inst
mcmc_mat
names_params
names_stats
load_all()
# Format stan output
stan_out <- format_mcmc_mat(mcmc_mat = stan_mat, names_params, names_stats,
keep_mcmc, runmcmc_out = runstan_out)
# Format stan output
stan_out <- format_mcmc_mat(mcmc_mat = stan_mat,# names_params, names_stats,
keep_mcmc, runmcmc_out = runstan_out)
# Glue together stan_out list with date and datetime information from
# original data_list input
stan_out$overall # Needs column for date
# Connect real dates to indexing numbers
par_inst$solar.time <- NA
par_inst
# Set first entry to start time
par_inst$solar.time[1] <- data_list$startTime
# Loop through time index to calc solar time at each timestep
for (i in 2:nrow(par_inst)){
par_inst$solar.time[i] <-
par_inst$solar.time[i-1] +
par_inst$timestep * 60
}
# Loop through time index to calc solar time at each timestep
for (i in 2:nrow(par_inst)){
par_inst$solar.time[i] <-
par_inst$solar.time[i-1] +
data_list$timestep * 60
}
par_inst
par_inst$solar.time
vignette(streamMetabolizer)
??streamMetabolizer
vignette("streamMetabolizer")
??vignette
vignettes("streamMetabolizer")
vignettes(streamMetabolizer)
??vignettes
browseVignettes(streamMetabolizer)
browseVignettes("streamMetabolizer")
vignette(package = "streamMetabolizer")
vignette(models_bayes, package = "streamMetabolizer")
vignette("models_bayes", package = "streamMetabolizer")
